#+TITLE: Kafka 
#+DATE: 2012-03-23
#+KEYWORDS: 日志收集

* Introduction

* 资料收集
** 文档
- [[http://kafka.apache.org/documentation.html][Kafka Documentation]]

** 论文
- [[http://research.microsoft.com/en-us/um/people/srikanth/netdb11/netdb11papers/netdb11-final12.pdf][Kafka: a Distributed Messaging System for Log Processing]]

** 文章
- [[http://tech.meituan.com/kafka-fs-design-theory.html][Kafka 文件存储机制那些事 - 美团技术团队]]
- [[http://shift-alt-ctrl.iteye.com/blog/1930345][Apache kafka 原理与特性(0.8V)]]
  


* 存储引擎设计
** 分段和索引
将索引文件按照 message id 分段，并且文件名就是起始 message id 的名字。

单个索引文件记录了各个 message id 和在数据文件里的位置。

* 使用场景
- [[http://kafka.apache.org/documentation.html][Kafka Documentation]]

** Messaging
#+BEGIN_QUOTE
Kafka works well as a replacement for a more traditional message
broker. Message brokers are used for a variety of reasons (to decouple
processing from data producers, to buffer unprocessed messages, etc). In
comparison to most messaging systems Kafka has better throughput, built-in
partitioning, replication, and fault-tolerance which makes it a good
solution for large scale message processing applications.

In our experience messaging uses are often comparatively low-throughput,
but may require low end-to-end latency and often depend on the strong
durability guarantees Kafka provides.

In this domain Kafka is comparable to traditional messaging systems such as
ActiveMQ or RabbitMQ.
#+END_QUOTE
   
** Website Activity Tracking
#+BEGIN_QUOTE
The original use case for Kafka was to be able to rebuild a user activity
tracking pipeline as a set of real-time publish-subscribe feeds. This means
site activity (page views, searches, or other actions users may take) is
published to central topics with one topic per activity type. These feeds
are available for subscription for a range of use cases including real-time
processing, real-time monitoring, and loading into Hadoop or offline data
warehousing systems for offline processing and reporting.

Activity tracking is often very high volume as many activity messages are
generated for each user page view.
#+END_QUOTE
** Metrics
#+BEGIN_QUOTE
Kafka is often used for operational monitoring data. This involves
aggregating statistics from distributed applications to produce centralized
feeds of operational data.
#+END_QUOTE
   
** Log Aggregation
#+BEGIN_QUOTE
Many people use Kafka as a replacement for a log aggregation solution. Log
aggregation typically collects physical log files off servers and puts them
in a central place (a file server or HDFS perhaps) for processing. Kafka
abstracts away the details of files and gives a cleaner abstraction of log
or event data as a stream of messages. This allows for lower-latency
processing and easier support for multiple data sources and distributed
data consumption. In comparison to log-centric systems like Scribe or
Flume, Kafka offers equally good performance, stronger durability
guarantees due to replication, and much lower end-to-end latency.
#+END_QUOTE
   
** Stream Processing
#+BEGIN_QUOTE
Many users end up doing stage-wise processing of data where data is
consumed from topics of raw data and then aggregated, enriched, or
otherwise transformed into new Kafka topics for further consumption. For
example a processing flow for article recommendation might crawl article
content from RSS feeds and publish it to an "articles" topic; further
processing might help normalize or deduplicate this content to a topic of
cleaned article content; a final stage might attempt to match this content
to users. This creates a graph of real-time data flow out of the individual
topics. Storm and Samza are popular frameworks for implementing these kinds
of transformations.
#+END_QUOTE

** Event Sourcing
#+BEGIN_QUOTE
Event sourcing is a style of application design where state changes are
logged as a time-ordered sequence of records. Kafka's support for very
large stored log data makes it an excellent backend for an application
built in this style.
#+END_QUOTE

** Commit Log
#+BEGIN_QUOTE
Kafka can serve as a kind of external commit-log for a distributed
system. The log helps replicate data between nodes and acts as a re-syncing
mechanism for failed nodes to restore their data. The log compaction
feature in Kafka helps support this usage. In this usage Kafka is similar
to Apache BookKeeper project.
#+END_QUOTE
* 源码阅读
* Kafka Monitor
- [[https://github.com/linkedin/kafka-monitor][linkedin/kafka-monitor: Monitor the availability of Kakfa clusters with generated messages.]]
  
#+BEGIN_EXAMPLE
Kafka Monitor is a framework to implement and execute long-running kafka system tests in a real cluster. It complements Kafka’s existing system tests by capturing potential bugs or regressions that are only likely to occur after prolonged period of time or with low probability. Moreover, it allows you to monitor Kafka cluster using end-to-end pipelines to obtain a number of derived vital stats such as end-to-end latency, service availability and message loss rate. 
#+END_EXAMPLE

** Metrics和JMX
- [[https://www.ibm.com/developerworks/cn/java/j-lo-jse63/][Java SE 6 新特性: JMX 与系统管理]]

1. 五种Metrics类型：Gauges/Counter/Meters/Histograms（直方图数据）/Timers。
2. Health Checks。
- [[https://www.cnblogs.com/nexiyi/p/metrics_sample_1.html][Metrics-Java版的指标度量工具之一 - 残雪余香 - 博客园]]
- [[http://www.cnblogs.com/nexiyi/p/3558271.html][Metrics-Java版的指标度量工具之二 - 残雪余香 - 博客园]]
