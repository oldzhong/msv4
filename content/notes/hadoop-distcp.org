#+TITLE: Hadoop DistCp
#+DATE: 2019-07-21
#+KEYWORDS: Hadoop

- [[https://hadoop.apache.org/docs/current/hadoop-distcp/DistCp.html][Apache Hadoop Distributed Copy – DistCp Version2 Guide]]

* 研究源码
** distcp命令行解析过程 <2019-07-26 五 11:00>
入口在DistCp.java的run(String[] argv)里面，先用 ~OptionsParser~ 来处理
argv参数列表，OptionsParser内部使用CommandLineParser来做解析。解析然
后，返回 ~DistCpOptions~ ，然后使用DistCpOptions构造 ~DistCpContext~
实例，DistCpContext是DistCpOptions的一层封装，将options封装为方法，方
便使用。

代码如下：
#+BEGIN_SRC java
  /**
   * Implementation of Tool::run(). Orchestrates the copy of source file(s)
   * to target location, by:
   *  1. Creating a list of files to be copied to target.
   *  2. Launching a Map-only job to copy the files. (Delegates to execute().)
   * @param argv List of arguments passed to DistCp, from the ToolRunner.
   * @return On success, it returns 0. Else, -1.
   */
  @Override
  public int run(String[] argv) {
    if (argv.length < 1) {
      OptionsParser.usage();
      return DistCpConstants.INVALID_ARGUMENT;
    }
    
    try {
      context = new DistCpContext(OptionsParser.parse(argv));
      checkSplitLargeFile();
      setTargetPathExists();
    } catch (Throwable e) {
      System.err.println("Invalid arguments: " + e.getMessage());
      OptionsParser.usage();      
      return DistCpConstants.INVALID_ARGUMENT;
    }
    
    try {
      execute();
    } catch (Inva
      ...
#+END_SRC

** 划分过程

** 文件copy的实现 <2019-07-22 一 17:15>
核心过程在 ~hadoop-distcp~ 下面的
~mapred/RetriableFileCopyCommand.java~ 文件里的copyBytes() 方法。源码
如下：
#+BEGIN_SRC java
@VisibleForTesting
  long copyBytes(CopyListingFileStatus source2, long sourceOffset,
      OutputStream outStream, int bufferSize, Mapper.Context context)
      throws IOException {
    Path source = source2.getPath();
    byte buf[] = new byte[bufferSize];
    ThrottledInputStream inStream = null;
    long totalBytesRead = 0;

    long chunkLength = source2.getChunkLength();
    boolean finished = false;
    try {
      inStream = getInputStream(source, context.getConfiguration());
      seekIfRequired(inStream, sourceOffset);
      int bytesRead = readBytes(inStream, buf);
      while (bytesRead >= 0) {
        if (chunkLength > 0 &&
            (totalBytesRead + bytesRead) >= chunkLength) {
          bytesRead = (int)(chunkLength - totalBytesRead);
          finished = true;
        }
        totalBytesRead += bytesRead;
        if (action == FileAction.APPEND) {
          sourceOffset += bytesRead;
        }
        outStream.write(buf, 0, bytesRead);
        updateContextStatus(totalBytesRead, context, source2);
        if (finished) {
          break;
        }
        bytesRead = readBytes(inStream, buf);
      }
      outStream.close();
      outStream = null;
    } finally {
      IOUtils.cleanupWithLogger(LOG, outStream, inStream);
    }
    return totalBytesRead;
  }
#+END_SRC

该方法的将源文件通过ThrottledInputStream打开，读取，并写到
BufferedOutputStream里面。

#+BEGIN_SRC java
  private static ThrottledInputStream getInputStream(Path path,
      Configuration conf) throws IOException {
    try {
      FileSystem fs = path.getFileSystem(conf);
      float bandwidthMB = conf.getFloat(DistCpConstants.CONF_LABEL_BANDWIDTH_MB,
              DistCpConstants.DEFAULT_BANDWIDTH_MB);
      FSDataInputStream in = fs.open(path);
      return new ThrottledInputStream(in, bandwidthMB * 1024 * 1024);
    }
    catch (IOException e) {
      throw new CopyReadException(e);
    }
  }
#+END_SRC
